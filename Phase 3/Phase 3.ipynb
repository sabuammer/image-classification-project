{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"../data/X.csv\", sep=' ', header=None, dtype=float)\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.read_csv(\"../data/y_bush_vs_others.csv\", header=None)\n",
    "y_bush = y.values.ravel()\n",
    "y = pd.read_csv(\"../data/y_williams_vs_others.csv\", header=None)\n",
    "y_williams = y.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bush, X_test_bush, y_train_bush, y_test_bush = train_test_split(X, \n",
    "                                                                        y_bush, \n",
    "                                                                        test_size=1./3, \n",
    "                                                                        random_state=3152, \n",
    "                                                                        shuffle=True, \n",
    "                                                                        stratify=y_bush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bush = X_train_bush.reshape(8822,64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bush = X_test_bush.reshape(4411, 64, 64, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TRIAL 1 ###\n",
    "\n",
    "# Create the model\n",
    "\n",
    "bush_model = Sequential()\n",
    "\n",
    "# Add model layers\n",
    "\n",
    "bush_model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(64,64,1)))\n",
    "bush_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "bush_model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "bush_model.add(Flatten())\n",
    "bush_model.add(Dense(8, activation='relu'))\n",
    "bush_model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "bush_model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8822/8822 [==============================] - 21s 2ms/step - loss: 0.1664\n",
      "Epoch 2/3\n",
      "8822/8822 [==============================] - 20s 2ms/step - loss: 0.1194\n",
      "Epoch 3/3\n",
      "8822/8822 [==============================] - 22s 2ms/step - loss: 0.0863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x125ce3358>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bush_model.fit(X_train_bush, y_train_bush, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bush_train_pred = bush_model.predict(X_train_bush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred_bush = np.array([1 if val > 0.5 else 0 for val in y_bush_train_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bush_f1_train = f1_score(y_train_bush, y_train_pred_bush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7807017543859649"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bush_f1_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bush_test_pred = bush_model.predict(X_test_bush)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bush_test_pred = np.array([1 if val > 0.5 else 0 for val in y_bush_test_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_bush_f1_test = f1_score(y_test_bush, y_bush_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6102719033232628"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bush_f1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIVIDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NECESSARY IMPORTS\n",
    "\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION OF THE DATA\n",
    "\n",
    "X = pd.read_csv(\"../data/X.csv\", sep=' ', header=None, dtype=float)\n",
    "X = X.values\n",
    "y = pd.read_csv(\"../data/y_bush_vs_others.csv\", header=None)\n",
    "y_bush = y.values.ravel()\n",
    "y = pd.read_csv(\"../data/y_williams_vs_others.csv\", header=None)\n",
    "y_williams = y.values.ravel()\n",
    "X_train_bush, X_test_bush, y_train_bush, y_test_bush = train_test_split(X, \n",
    "                                                                        y_bush, \n",
    "                                                                        test_size=1./3, \n",
    "                                                                        random_state=3152, \n",
    "                                                                        shuffle=True, \n",
    "                                                                        stratify=y_bush)\n",
    "\n",
    "X_train_bush = X_train_bush.reshape(len(X_train_bush),64,64,1)\n",
    "X_test_bush = X_test_bush.reshape(len(X_test_bush),64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "8822/8822 [==============================] - 5s 606us/step - loss: 0.1744\n",
      "Epoch 2/25\n",
      "8822/8822 [==============================] - 5s 533us/step - loss: 0.1328\n",
      "Epoch 3/25\n",
      "8822/8822 [==============================] - 5s 554us/step - loss: 0.0988\n",
      "Epoch 4/25\n",
      "8822/8822 [==============================] - 5s 553us/step - loss: 0.0763\n",
      "Epoch 5/25\n",
      "8822/8822 [==============================] - 5s 585us/step - loss: 0.0636\n",
      "Epoch 6/25\n",
      "8822/8822 [==============================] - 5s 571us/step - loss: 0.0514\n",
      "Epoch 7/25\n",
      "8822/8822 [==============================] - 5s 556us/step - loss: 0.0445\n",
      "Epoch 8/25\n",
      "8822/8822 [==============================] - 5s 553us/step - loss: 0.0386\n",
      "Epoch 9/25\n",
      "8822/8822 [==============================] - 5s 566us/step - loss: 0.0304\n",
      "Epoch 10/25\n",
      "8822/8822 [==============================] - 5s 579us/step - loss: 0.0300\n",
      "Epoch 11/25\n",
      "8822/8822 [==============================] - 5s 590us/step - loss: 0.0231\n",
      "Epoch 12/25\n",
      "8822/8822 [==============================] - 5s 598us/step - loss: 0.0189\n",
      "Epoch 13/25\n",
      "8822/8822 [==============================] - 5s 613us/step - loss: 0.0162\n",
      "Epoch 14/25\n",
      "8822/8822 [==============================] - 5s 601us/step - loss: 0.0140\n",
      "Epoch 15/25\n",
      "8822/8822 [==============================] - 5s 601us/step - loss: 0.0123\n",
      "Epoch 16/25\n",
      "8822/8822 [==============================] - 5s 617us/step - loss: 0.0103\n",
      "Epoch 17/25\n",
      "8822/8822 [==============================] - 6s 633us/step - loss: 0.0090\n",
      "Epoch 18/25\n",
      "8822/8822 [==============================] - 5s 592us/step - loss: 0.0080\n",
      "Epoch 19/25\n",
      "8822/8822 [==============================] - 5s 580us/step - loss: 0.0061\n",
      "Epoch 20/25\n",
      "8822/8822 [==============================] - 5s 574us/step - loss: 0.0050\n",
      "Epoch 21/25\n",
      "8822/8822 [==============================] - 5s 585us/step - loss: 0.0047\n",
      "Epoch 22/25\n",
      "8822/8822 [==============================] - 5s 590us/step - loss: 0.0050\n",
      "Epoch 23/25\n",
      "8822/8822 [==============================] - 5s 573us/step - loss: 0.0033\n",
      "Epoch 24/25\n",
      "8822/8822 [==============================] - 5s 579us/step - loss: 0.0025\n",
      "Epoch 25/25\n",
      "8822/8822 [==============================] - 5s 561us/step - loss: 0.0022\n",
      "F1 score for bush model on train: 0.9985815602836879, F1 score for bush model on test: 0.673913043478261\n"
     ]
    }
   ],
   "source": [
    "### TRIAL 1 ###\n",
    "\n",
    "# Create the model\n",
    "\n",
    "bush_model = Sequential()\n",
    "\n",
    "# Add model layers\n",
    "\n",
    "bush_model.add(Conv2D(16, kernel_size=4, activation='relu', input_shape=(64,64,1)))\n",
    "bush_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "bush_model.add(Flatten())\n",
    "bush_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "bush_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "bush_model.fit(X_train_bush, y_train_bush, epochs=25, batch_size=32)\n",
    "\n",
    "y_bush_train_pred = bush_model.predict(X_train_bush)\n",
    "y_bush_train_pred = np.array([1 if val > 0.5 else 0 for val in y_bush_train_pred])\n",
    "y_bush_f1_train = f1_score(y_train_bush, y_bush_train_pred)\n",
    "\n",
    "y_bush_test_pred = bush_model.predict(X_test_bush)\n",
    "y_bush_test_pred = np.array([1 if val > 0.5 else 0 for val in y_bush_test_pred])\n",
    "y_bush_f1_test = f1_score(y_test_bush, y_bush_test_pred)\n",
    "\n",
    "print(\"F1 score for bush model on train: {}, F1 score for bush model on test: {}\".format(y_bush_f1_train, y_bush_f1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8822/8822 [==============================] - 9s 999us/step - loss: 0.1721\n",
      "Epoch 2/5\n",
      "8822/8822 [==============================] - 7s 787us/step - loss: 0.1204\n",
      "Epoch 3/5\n",
      "8822/8822 [==============================] - 7s 807us/step - loss: 0.0812\n",
      "Epoch 4/5\n",
      "8822/8822 [==============================] - 7s 808us/step - loss: 0.0507\n",
      "Epoch 5/5\n",
      "8822/8822 [==============================] - 7s 810us/step - loss: 0.0359\n",
      "F1 score for bush model on train: 0.9565217391304348, F1 score for bush model on test: 0.7162162162162163\n"
     ]
    }
   ],
   "source": [
    "## TRIAL 2 ###\n",
    "\n",
    "# Create the model\n",
    "\n",
    "bush_model2 = Sequential()\n",
    "\n",
    "# Add model layers\n",
    "\n",
    "bush_model2.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(64,64,1)))\n",
    "bush_model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "bush_model2.add(Flatten())\n",
    "bush_model2.add(Dense(16, activation='relu'))\n",
    "bush_model2.add(Dense(8, activation='relu'))\n",
    "bush_model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "bush_model2.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "bush_model2.fit(X_train_bush, y_train_bush, epochs=5, batch_size=32)\n",
    "\n",
    "y_bush_train_pred2 = bush_model2.predict(X_train_bush)\n",
    "y_bush_train_pred2 = np.array([1 if val > 0.5 else 0 for val in y_bush_train_pred2])\n",
    "y_bush_f1_train2 = f1_score(y_train_bush, y_bush_train_pred2)\n",
    "\n",
    "y_bush_test_pred2 = bush_model2.predict(X_test_bush)\n",
    "y_bush_test_pred2 = np.array([1 if val > 0.5 else 0 for val in y_bush_test_pred2])\n",
    "y_bush_f1_test2 = f1_score(y_test_bush, y_bush_test_pred2)\n",
    "\n",
    "print(\"F1 score for bush model on train: {}, F1 score for bush model on test: {}\".format(y_bush_f1_train2, y_bush_f1_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = load_model('bush_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for bush model on train: 0.9565217391304348, F1 score for bush model on test: 0.7162162162162163\n"
     ]
    }
   ],
   "source": [
    "y_bush_train_pred2 = m1.predict(X_train_bush)\n",
    "y_bush_train_pred2 = np.array([1 if val > 0.5 else 0 for val in y_bush_train_pred2])\n",
    "y_bush_f1_train2 = f1_score(y_train_bush, y_bush_train_pred2)\n",
    "\n",
    "y_bush_test_pred2 = m1.predict(X_test_bush)\n",
    "y_bush_test_pred2 = np.array([1 if val > 0.5 else 0 for val in y_bush_test_pred2])\n",
    "y_bush_f1_test2 = f1_score(y_test_bush, y_bush_test_pred2)\n",
    "\n",
    "print(\"F1 score for bush model on train: {}, F1 score for bush model on test: {}\".format(y_bush_f1_train2, y_bush_f1_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.save('bush.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "bush_f1 = [0.9565217391304348, 0.7162162162162163]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(bush_f1, open('bush.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Williams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARATION OF THE DATA\n",
    "\n",
    "X_train_williams, X_test_williams, y_train_williams, y_test_williams = train_test_split(X, \n",
    "                                                                        y_williams, \n",
    "                                                                        test_size=1./3, \n",
    "                                                                        random_state=3152, \n",
    "                                                                        shuffle=True, \n",
    "                                                                        stratify=y_williams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_williams = X_train_williams.reshape(len(X_train_williams),64,64,1)\n",
    "X_test_williams = X_test_williams.reshape(len(X_test_williams),64,64,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "8822/8822 [==============================] - 6s 708us/step - loss: 0.0363\n",
      "Epoch 2/5\n",
      "8822/8822 [==============================] - 6s 713us/step - loss: 0.0163\n",
      "Epoch 3/5\n",
      "8822/8822 [==============================] - 7s 760us/step - loss: 0.0070\n",
      "Epoch 4/5\n",
      "8822/8822 [==============================] - 7s 741us/step - loss: 0.0048\n",
      "Epoch 5/5\n",
      "8822/8822 [==============================] - 6s 711us/step - loss: 0.0035\n",
      "F1 score for williams model on train: 0.9705882352941176, F1 score for williams model on test: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "## TRIAL 1 ###\n",
    "\n",
    "# Create the model\n",
    "\n",
    "williams_model = Sequential()\n",
    "\n",
    "# Add model layers\n",
    "\n",
    "williams_model.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(64,64,1)))\n",
    "williams_model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "williams_model.add(Flatten())\n",
    "williams_model.add(Dense(16, activation='relu'))\n",
    "williams_model.add(Dense(8, activation='relu'))\n",
    "williams_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "williams_model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "williams_model.fit(X_train_williams, y_train_williams, epochs=5, batch_size=32)\n",
    "\n",
    "y_williams_train_pred = williams_model.predict(X_train_williams)\n",
    "y_williams_train_pred = np.array([1 if val > 0.5 else 0 for val in y_williams_train_pred])\n",
    "y_williams_f1_train = f1_score(y_train_williams, y_williams_train_pred)\n",
    "\n",
    "y_williams_test_pred = williams_model.predict(X_test_williams)\n",
    "y_williams_test_pred = np.array([1 if val > 0.5 else 0 for val in y_williams_test_pred])\n",
    "y_williams_f1_test = f1_score(y_test_williams, y_williams_test_pred)\n",
    "\n",
    "print(\"F1 score for williams model on train: {}, F1 score for williams model on test: {}\".format(y_williams_f1_train, y_williams_f1_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "williams_model.save('williams.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = load_model('williams.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for williams model on train: 0.9705882352941176, F1 score for williams model on test: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "y_williams_train_pred = m1.predict(X_train_williams)\n",
    "y_williams_train_pred = np.array([1 if val > 0.5 else 0 for val in y_williams_train_pred])\n",
    "y_williams_f1_train = f1_score(y_train_williams, y_williams_train_pred)\n",
    "\n",
    "y_williams_test_pred = m1.predict(X_test_williams)\n",
    "y_williams_test_pred = np.array([1 if val > 0.5 else 0 for val in y_williams_test_pred])\n",
    "y_williams_f1_test = f1_score(y_test_williams, y_williams_test_pred)\n",
    "\n",
    "print(\"F1 score for williams model on train: {}, F1 score for williams model on test: {}\".format(y_williams_f1_train, y_williams_f1_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "williams_f1 = [0.9705882352941176, 0.5833333333333334]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(williams_f1, open('williams.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8822/8822 [==============================] - 7s 813us/step - loss: 0.0307 - acc: 0.9959\n",
      "Epoch 2/10\n",
      "8822/8822 [==============================] - 6s 733us/step - loss: 0.0143 - acc: 0.9960\n",
      "Epoch 3/10\n",
      "8822/8822 [==============================] - 7s 757us/step - loss: 0.0103 - acc: 0.9967\n",
      "Epoch 4/10\n",
      "8822/8822 [==============================] - 7s 758us/step - loss: 0.0069 - acc: 0.9978\n",
      "Epoch 5/10\n",
      "8822/8822 [==============================] - 7s 751us/step - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 6/10\n",
      "8822/8822 [==============================] - 7s 752us/step - loss: 0.0033 - acc: 0.9991\n",
      "Epoch 7/10\n",
      "8822/8822 [==============================] - 7s 756us/step - loss: 6.6397e-04 - acc: 0.9998\n",
      "Epoch 8/10\n",
      "8822/8822 [==============================] - 7s 754us/step - loss: 1.6356e-04 - acc: 1.0000\n",
      "Epoch 9/10\n",
      "8822/8822 [==============================] - 7s 768us/step - loss: 4.5959e-05 - acc: 1.0000\n",
      "Epoch 10/10\n",
      "8822/8822 [==============================] - 7s 764us/step - loss: 3.0604e-05 - acc: 1.0000\n",
      "F1 score for williams model on train: 1.0, F1 score for williams model on test: 0.5833333333333334\n"
     ]
    }
   ],
   "source": [
    "# TRIAL 2 ###\n",
    "\n",
    "# Create the model\n",
    "\n",
    "williams_model2 = Sequential()\n",
    "\n",
    "# Add model layers\n",
    "\n",
    "williams_model2.add(Conv2D(32, kernel_size=3, activation='relu', input_shape=(64,64,1)))\n",
    "williams_model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "williams_model2.add(Flatten())\n",
    "williams_model2.add(Dense(16, activation='relu'))\n",
    "williams_model2.add(Dense(8, activation='relu'))\n",
    "williams_model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "williams_model2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "williams_model2.fit(X_train_williams, y_train_williams, epochs=10, batch_size=32)\n",
    "\n",
    "y_williams_train_pred2 = williams_model2.predict(X_train_williams)\n",
    "y_williams_train_pred2 = np.array([1 if val > 0.5 else 0 for val in y_williams_train_pred2])\n",
    "y_williams_f1_train2 = f1_score(y_train_williams, y_williams_train_pred2)\n",
    "\n",
    "y_williams_test_pred2 = williams_model2.predict(X_test_williams)\n",
    "y_williams_test_pred2 = np.array([1 if val > 0.5 else 0 for val in y_williams_test_pred2])\n",
    "y_williams_f1_test2 = f1_score(y_test_williams, y_williams_test_pred2)\n",
    "\n",
    "print(\"F1 score for williams model on train: {}, F1 score for williams model on test: {}\".format(y_williams_f1_train2, y_williams_f1_test2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
